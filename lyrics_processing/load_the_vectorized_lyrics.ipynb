{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "\n",
    "import chromadb.utils.embedding_functions as embedding_functions\n",
    "import chromadb\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and load the .env file\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "# Define the embedding model to use\n",
    "EMBEDDING_MODEL_NAME = \"text-embedding-3-small\"\n",
    "embeddings = OpenAIEmbeddings(model=EMBEDDING_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load the documents from the Chroma database\n",
    "\n",
    "# Load the documents from the Chroma database\n",
    "# Stored in the chroma_db folder with the collection name \"lyrics\"\n",
    "# The OpenAI embeddings model is used as the embedding function\n",
    "vectorstore = Chroma(\n",
    "    persist_directory=\"./chroma_db\",\n",
    "    collection_name=\"lyrics\",\n",
    "    embedding_function=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get the metadata and documents and count them\n",
    "\n",
    "# Get the metadata and documents from the loaded vectorstore collection\n",
    "vectorstore_elements_dict = vectorstore._collection.get(\n",
    "    include=[\"metadatas\", \"documents\"]\n",
    ")\n",
    "print(f\"Number of documents in the vectorstore: {vectorstore._collection.count()}\")\n",
    "print(f\"Name of the loaded collection: {vectorstore._collection.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split the collection into parts and save them in separate databases to avoid memory issues\n",
    "\n",
    "# Define the OpenAI embedding function\n",
    "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"), model_name=EMBEDDING_MODEL_NAME\n",
    ")\n",
    "\n",
    "# Load the original collection with all the documents\n",
    "client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "original_collection = client.get_collection(\"lyrics\")\n",
    "\n",
    "# Get the ids of the documents in the original collection to shuffle them and split them into parts\n",
    "ids = original_collection.get(include=[])[\"ids\"]\n",
    "\n",
    "# Shuffle the ids and split them into 5 parts\n",
    "parts_number = 5\n",
    "random.shuffle(ids)\n",
    "part_size = len(ids) // parts_number\n",
    "ids_parts = [ids[i : i + part_size] for i in range(0, len(ids), part_size)]\n",
    "\n",
    "# If there are more than 5 parts, then merge the last two parts into one\n",
    "if len(ids_parts) > parts_number:\n",
    "    ids_parts[-2] += ids_parts[-1]\n",
    "    ids_parts = ids_parts[:-1]\n",
    "\n",
    "# Create a new collection for each part\n",
    "# Add the documents to the new collection in chunks of 1000 documents to avoid memory issues\n",
    "# Save the collections in separate databases\n",
    "for i, ids_part in enumerate(ids_parts):\n",
    "    part_client = chromadb.PersistentClient(path=f\"./chroma_db_part{i+1}\")\n",
    "    new_collection_name = \"lyrics\"\n",
    "    new_collection = part_client.create_collection(\n",
    "        name=new_collection_name, embedding_function=openai_ef\n",
    "    )\n",
    "\n",
    "    chunk_size = 1000\n",
    "    ids_part_chunks = [\n",
    "        ids_part[i : i + chunk_size] for i in range(0, len(ids_part), chunk_size)\n",
    "    ]\n",
    "    chunks_num = len(ids_part_chunks)\n",
    "    for j, ids in enumerate(ids_part_chunks):\n",
    "        item = original_collection.get(\n",
    "            ids=ids, include=[\"metadatas\", \"documents\", \"embeddings\"]\n",
    "        )\n",
    "        item.pop(\"data\")\n",
    "        item.pop(\"included\")\n",
    "        new_collection.add(**item)\n",
    "        print(f\"Added document {j+1}/{chunks_num} from part {i+1}\")\n",
    "\n",
    "    print(f\"Created collection {new_collection_name} with {len(ids_part)} documents\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
